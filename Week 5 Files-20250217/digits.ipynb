{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a dataset of handwritten digits from 0 to 9\n",
    "\n",
    "We need some library to read the images, I've chosen the pillow library which comes with Anaconda, if you need to \n",
    "\n",
    "pip install Pillow\n",
    "\n",
    "should install it for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 10\n",
    "\n",
    "##Printing Examples\n",
    "def printexamples(X):\n",
    "    examples_per_class = 10\n",
    "    pos = 0\n",
    "    for cls in range(number_of_classes):\n",
    "        idxs = range(pos,pos+500)\n",
    "        idxs = np.random.choice(idxs, examples_per_class, replace=False)\n",
    "        for i, idx in enumerate(idxs):\n",
    "            plt.subplot(examples_per_class, number_of_classes, i * number_of_classes + cls + 1)\n",
    "            plt.imshow(X[idx].reshape(20,20).astype('uint8'), cmap='gray')\n",
    "            plt.axis('off')\n",
    "            if i == 0:\n",
    "                plt.title(str(cls))\n",
    "        pos = pos+500\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (5000, 400)\n",
      "Shape of y: (5000,)\n",
      "First 10 labels: [0 0 0 0 0 0 0 0 0 0]\n",
      "Training set size: (3000, 400) (3000,)\n",
      "Validation set size: (1000, 400) (1000,)\n",
      "Test set size: (1000, 400) (1000,)\n"
     ]
    }
   ],
   "source": [
    "##PART 1 Preparing The Data\n",
    "\n",
    "# get the list of all the files in digits.zip/data and create filelist\n",
    "filelist = sorted(glob.glob('data/*/*.png'))\n",
    "\n",
    "#create a file list\n",
    "X = np.array([np.array(Image.open(f).convert('L').resize((20, 20))).flatten() for f in filelist]) / 255.0 # normalize pixels\n",
    "\n",
    "# Step 3: Extract class labels from filenames\n",
    "# Assuming filenames are like 'category_0_image1.jpg', 'category_1_image2.jpg', etc.\n",
    "#y = np.array([int(os.path.basename(f).split('_')[1]) for f in filelist])\n",
    "\n",
    "y = np.array([int(os.path.basename(os.path.dirname(f))) for f in filelist])\n",
    "# Step 4: Ensure X and y are properly structured\n",
    "print(\"Shape of X:\", X.shape)  # Should be (5000, 400)\n",
    "print(\"Shape of y:\", y.shape)  # Should be (5000,)\n",
    "print(\"First 10 labels:\", y[:10])  # Check labels\n",
    "\n",
    "a = [s.split() for s in \" \".join(filelist).split(\"\\\\\") if s]\n",
    "#a = np.array(filename.split('\\\\')[1] for filename in filelist, dtype=int)\n",
    "#print(a.shape)\n",
    "\n",
    "# Step 5: Split data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Step 6: Print shapes of datasets\n",
    "print(\"Training set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set size:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set size:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9567\n",
      "Validation Accuracy: 0.9360\n",
      "Incorrect predictions: 68\n"
     ]
    }
   ],
   "source": [
    "## PART 2 K-Nearest Neighbors\n",
    "# Step 1: Train k-NN model with k=5\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Step 2: Evaluate the model\n",
    "train_score = knn.score(X_train, y_train)\n",
    "val_score = knn.score(X_val, y_val)\n",
    "print(f\"Training Accuracy: {train_score:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_score:.4f}\")\n",
    "\n",
    "# Step 3: Count incorrect predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "incorrect_predictions = (y_pred != y_test).sum()\n",
    "print(f\"Incorrect predictions: {incorrect_predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       121\n",
      "           1       0.91      0.99      0.95        94\n",
      "           2       0.99      0.90      0.94       101\n",
      "           3       0.91      0.89      0.90       102\n",
      "           4       0.93      0.93      0.93        95\n",
      "           5       0.96      0.93      0.95       103\n",
      "           6       0.98      0.98      0.98        91\n",
      "           7       0.91      0.92      0.91        98\n",
      "           8       0.91      0.89      0.90       104\n",
      "           9       0.84      0.88      0.86        91\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.93      0.93      0.93      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[121   0   0   0   0   0   0   0   0   0]\n",
      " [  0  93   0   0   0   1   0   0   0   0]\n",
      " [  1   1  91   1   0   0   0   4   3   0]\n",
      " [  0   0   0  91   0   2   1   0   5   3]\n",
      " [  0   2   1   0  88   0   1   0   0   3]\n",
      " [  0   1   0   3   0  96   0   0   1   2]\n",
      " [  2   0   0   0   0   0  89   0   0   0]\n",
      " [  0   2   0   0   2   0   0  90   0   4]\n",
      " [  0   2   0   3   2   1   0   0  93   3]\n",
      " [  0   1   0   2   3   0   0   5   0  80]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k found: 4\n",
      "Final validation accuracy with k=4: 0.9350\n"
     ]
    }
   ],
   "source": [
    "# Step 6: k-Fold Cross Validation to find best k\n",
    "k_values = list(range(1, 21))\n",
    "k_scores = [cross_val_score(KNeighborsClassifier(n_neighbors=k), X_train, y_train, cv=5).mean() for k in k_values]\n",
    "best_k = k_values[np.argmax(k_scores)]\n",
    "print(f\"Best k found: {best_k}\")\n",
    "\n",
    "# Train final model with best k\n",
    "knn_best = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_best.fit(X_train, y_train)\n",
    "final_val_score = knn_best.score(X_val, y_val)\n",
    "print(f\"Final validation accuracy with k={best_k}: {final_val_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       121\n",
      "           1       0.90      0.99      0.94        94\n",
      "           2       0.98      0.91      0.94       101\n",
      "           3       0.93      0.91      0.92       102\n",
      "           4       0.90      0.94      0.92        95\n",
      "           5       0.93      0.92      0.93       103\n",
      "           6       0.98      0.98      0.98        91\n",
      "           7       0.90      0.92      0.91        98\n",
      "           8       0.94      0.88      0.91       104\n",
      "           9       0.88      0.85      0.86        91\n",
      "\n",
      "    accuracy                           0.93      1000\n",
      "   macro avg       0.93      0.93      0.93      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final classification report\n",
    "y_pred_best = knn_best.predict(X_test)\n",
    "print(\"Final Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best C found: 0.3593813663804626\n",
      "Validation Accuracy for Logistic Regression: 0.8960\n"
     ]
    }
   ],
   "source": [
    "## PART 3 Logistical Regression\n",
    "\n",
    "# Step 1: Use kFold Cross Validation to choose the best regularization strength\n",
    "c_values = np.logspace(-4, 4, 10)\n",
    "c_scores = [cross_val_score(LogisticRegression(C=c, max_iter=1000), X_train, y_train, cv=5).mean() for c in c_values]\n",
    "best_c = c_values[np.argmax(c_scores)]\n",
    "print(f\"Best C found: {best_c}\")\n",
    "\n",
    "# Step 2: Train the best logistic regression model\n",
    "log_reg = LogisticRegression(C=best_c, max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Step 3: Evaluate logistic regression model\n",
    "y_pred_log = log_reg.predict(X_test)\n",
    "log_val_score = log_reg.score(X_val, y_val)\n",
    "print(f\"Validation Accuracy for Logistic Regression: {log_val_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       121\n",
      "           1       0.93      0.96      0.94        94\n",
      "           2       0.89      0.85      0.87       101\n",
      "           3       0.88      0.82      0.85       102\n",
      "           4       0.88      0.89      0.89        95\n",
      "           5       0.87      0.85      0.86       103\n",
      "           6       0.94      0.98      0.96        91\n",
      "           7       0.91      0.87      0.89        98\n",
      "           8       0.87      0.87      0.87       104\n",
      "           9       0.84      0.88      0.86        91\n",
      "\n",
      "    accuracy                           0.90      1000\n",
      "   macro avg       0.89      0.89      0.89      1000\n",
      "weighted avg       0.89      0.90      0.89      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Print classification report\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Confusion Matrix:\n",
      "[[118   0   0   0   0   2   1   0   0   0]\n",
      " [  0  90   0   1   0   0   0   0   2   1]\n",
      " [  1   0  86   2   2   1   1   3   4   1]\n",
      " [  0   1   6  84   0   3   1   0   7   0]\n",
      " [  2   1   0   0  85   0   2   1   1   3]\n",
      " [  1   2   0   5   6  88   1   0   0   0]\n",
      " [  2   0   0   0   0   0  89   0   0   0]\n",
      " [  0   2   1   1   0   1   0  85   0   8]\n",
      " [  0   1   4   2   1   4   0   0  90   2]\n",
      " [  2   0   0   0   3   2   0   4   0  80]]\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Print confusion matrix\n",
    "log_conf_matrix = confusion_matrix(y_test, y_pred_log)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(log_conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
